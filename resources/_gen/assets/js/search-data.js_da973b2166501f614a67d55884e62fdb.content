(function(){const pages=[{"idx":0,"href":"/01-software-development/","title":"Software Development","content":""},{"idx":1,"href":"/02-elixir/","title":"Elixir","content":""},{"idx":2,"href":"/03-blockchain/","title":"Blockchain","content":""},{"idx":3,"href":"/10-business/","title":"Business","content":""},{"idx":4,"href":"/80-life/","title":"Life","content":""},{"idx":5,"href":"/90-about/","title":"About","content":""},{"idx":6,"href":"/","title":"About","content":"Hi. My name is Unnawut. You may also know me by my Thai nickname, O (pronounced a neutral \u0026ldquo;Oh\u0026rdquo;).\nI\u0026rsquo;m currently working as a software engineer at OmiseGO on the Integration team. I make sure that concepts as fresh as blockchain and decentralized exchange are accessible by businesses and individuals worldwide. My primary work at OmiseGO is the development of the open-source, Elixir-based eWallet server.\nYou may find me on LinkedIn, Medium, TED, Facebook and Instagram.\nFor the geeks out there, you\u0026rsquo;ll probably know me better through Stack Overflow and Github.\nSecure ways to contact me can be found at keybase.io/unnawut.\n"},{"idx":7,"href":"/02-elixir/2019-10-05-genserver-registry-dynamic-supervisor-combined/","title":"GenServer, Registry, DynamicSupervisor. Combined.","content":" GenServer, Registry, DynamicSupervisor. Combined. Originally published at dev.to.\nIn omisego/ewallet, we\u0026rsquo;re building/refactoring a TransactionTracker that listens to a huge number of transactions (think money transactions) that also happen to be residing in an external source that is slow to update (Hello, Ethereum).\nSo we need a way for us to:\n Run the trackers concurrently, so to enable massive amount of transaction tracking. Look up a running tracker, so we can reuse it for different purposes. Automatically restart a specific tracker that goes wonky, because with external sources, anything can go wrong.  With Elixir and OTP/BEAM behind the scene, we are able to solve the problem by utilizing 3 Elixir core features:\n GenServer for building long-running, concurrent tasks. Registry for looking up those running GenServer\u0026rsquo;s. DynamicSupervisor for monitoring those arbitrary number of GenServer\u0026rsquo;s, and automatically restart one when it goes wonky.  The problem If we were to implement our own custom wiring, we would have to do the following:\n Start a new tracker process (a GenServer) attached to a DynamicSupervisor. Register the tracker process with the registry. To invoke the process, lookup the registry for the process ID. Make sure the registry handles the process\u0026rsquo;s crash, and remove the process from the registry. Make sure the registry knows when the process is restarted and registers the new process ID back. Deregister the process from the registry when it shuts down.  That\u0026rsquo;s a lot of code for the registry, and a lot of code to wire up the GenServer, DynamicSupervisor and Registry together. Since there\u0026rsquo;s a lot of moving parts, our implementation and wiring could be very prone to errors. All of this represents very little business value.\nThe solution Because Elixir designed the GenServer, Registry and DynamicSupervisor to work together seamlessly, we are surprised by how few lines of code needed to wire these up together.\ndefmodule TransactionTracker do use GenServer @registry TransactionTracker.Registry @supervisor TransactionTracker.TrackerSupervisor def start(transaction_id) do opts = [ transaction_id: transaction_id, name: {:via, Registry, {@registry, transaction_id}} ] DynamicSupervisor.start_child(@supervisor, {__MODULE__, opts}) end def lookup(transaction_id) do case Registry.lookup(@registry, transaction_id) do [{pid, _}] -\u0026gt; {:ok, pid} [] -\u0026gt; {:error, :not_found} end end def start_link(opts) do {name, opts} = Keyword.pop(opts, :name) GenServer.start_link(__MODULE__, opts, name: name) end def init(opts) do state = %{ transaction_id: Keyword.fetch!(opts, :transaction_id), } {:ok, state} end #... end defmodule TransactionTracker.Application do use Application def start(_type, _args) do children = [ {Registry, keys: :unique, name: TransactionTracker.Registry}, {DynamicSupervisor, name: TransactionTracker.TrackerSupervisor, strategy: :one_for_one} ] Supervisor.start_link(children, name: TransactionTracker.Supervisor, strategy: :one_for_one) end end With above, we can now do a simple one-liner to start the tracker:\niex\u0026gt; TransactionTracker.start(\u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;) {:ok, #PID\u0026lt;0.104.0\u0026gt;} This one-line call would automatically:\n Start a new TransactionTracker GenServer for the given transaction ID. Register the tracker with TransactionTracker.Registry. Register the tracker with TransactionTracker.TrackerSupervisor. Restart the tracker when it shuts down abnormally. Return the correct process ID lookup even after a tracker restart. Deregister the tracker on expected shutdown. Allow interactions with the process via the returned pid or by looking up: TransactionTracker.lookup(\u0026quot;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026quot;)  And this is what happens with an abnormal exit.\niex\u0026gt; TransactionTracker.start(\u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;) {:ok, #PID\u0026lt;0.157.0\u0026gt;} iex\u0026gt; {:ok, pid} = TransactionTracker.lookup(\u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;) {:ok, #PID\u0026lt;0.157.0\u0026gt;} iex\u0026gt; :ok = GenServer.stop(pid, :its_a_crash) 17:25:49.286 [error] GenServer {TransactionTracker.Registry, \u0026#34;abcd\u0026#34;} terminating ** (stop) :its_a_crash Last message: [] State: %{transaction_id: \u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;} iex\u0026gt; {:ok, restarted_pid} = TransactionTracker.lookup(\u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;) {:ok, #PID\u0026lt;0.162.0\u0026gt;} iex\u0026gt; :sys.get_state(restarted_pid) %{transaction_id: \u0026#34;txn_01dp371w0fnjhf9z2tjebx4vr4\u0026#34;} You would see that the lookup returns the new process automatically, and the process holds the same state as the previous one. Just start the process with your ideal identifier and you\u0026rsquo;ll be able to access the process from anywhere, with guarantee that it\u0026rsquo;ll point you to the correct process even if the process got restarted and the process ID changed.\nIsn\u0026rsquo;t it pretty?\nConclusion By using Elixir\u0026rsquo;s GenServer, Registry and DynamicSupervisor, we\u0026rsquo;re able to reap the following benefits when running long-running tasks.\n A one-liner way to start a long-running process, encapsulating away the registry and supervisor. The process, when it goes woowoo, gets restarted automatically by the supervisor. The registry handles a process\u0026rsquo;s shutdown automatically, so no need to worry about deregistering dead processes. The process can be looked up via the registry with ease, using our own arbitrary identifier, and works across process crashes.  What do you think? Do you have better ways to manage long-running processes? Let me know!\n"},{"idx":8,"href":"/tags/","title":"Tags","content":""},{"idx":9,"href":"/tags/concurrency/","title":"concurrency","content":""},{"idx":10,"href":"/tags/elixir/","title":"elixir","content":""},{"idx":11,"href":"/tags/programming/","title":"programming","content":""},{"idx":12,"href":"/tags/tech/","title":"tech","content":""},{"idx":13,"href":"/02-elixir/2019-09-29-clean-reusable-test-helpers-elixir-macros/","title":"Clean and reusable test helpers with Elixir macros","content":" Clean and reusable test helpers with Elixir macros Originally published at dev.to.\nSometimes, seemingly redundant tests could serve as an assurance that our code works. While it\u0026rsquo;s possible to abstract away the tests to a higher level, it may mean sacrificing readability.\nIn this post, I\u0026rsquo;d like to suggest a way to create test helpers that can be reused easily and works seamlessly with ExUnit. While we generally avoid creating macros as the official guide says:\n Macros should only be used as a last resort. Remember that explicit is better than implicit. Clear code is better than concise code.\n I believe this post presents an exact use case where macros allow us to have explicit, concise and clean tests at the same time.\nThe problem To begin, let\u0026rsquo;s say we have two schemas called User and Account. Each of them contain a name field that should not be blank. We could add tests like this:\ndefmodule UserTest do use ExUnit.Case describe \u0026#34;insert/1\u0026#34; do #... test \u0026#34;fails when given a blank name\u0026#34; do {:error, changeset} = User.insert(%{name: nil}) assert changeset.errors == [{:name, {\u0026#34;can\u0026#39;t be blank\u0026#34;, [validation: :required]}}] end end end defmodule AccountTest do use ExUnit.Case describe \u0026#34;insert/1\u0026#34; do #... test \u0026#34;fails when given a blank name\u0026#34; do {:error, changeset} = Account.insert(%{name: nil}) assert changeset.errors == [{:name, {\u0026#34;can\u0026#39;t be blank\u0026#34;, [validation: :required]}}] end end end Imagine if you have a dozen of schemas, most of which will require a check for blank fields. How much of your test code will be redundant? And how incomprehensible it would be, as the test code gets larger and larger?\nInterim solution: Helper functions The interim solution we tried was by abstracting away the assertion into a helper function, like below:\ndefmodule TestHelper do def not_blank(schema, field) do {result, changeset} = schema.insert(%{field =\u0026gt; nil}) assert result == :error assert changeset.errors == [{field, {\u0026#34;can\u0026#39;t be blank\u0026#34;, [validation: :required]}}] end end defmodule UserTest do use ExUnit.Case import TestHelper describe \u0026#34;insert/1\u0026#34; do #... test \u0026#34;fails when given a blank name\u0026#34; do assert not_blank(User, :name) end end end defmodule AccountTest do use ExUnit.Case import TestHelper describe \u0026#34;insert/1\u0026#34; do #... test \u0026#34;fails when given a blank name\u0026#34; do assert not_blank(Account, :name) end end end While above works great, the problem is that it is still cluttered when you want many assertions in a single test case, or you rather prefer lean test cases by testing one thing at a time.\nThe real deal: Macros as test helpers Here\u0026rsquo;s how we use macros to generate clean test cases:\ndefmodule TestHelper do defmacro test_insert_prevent_blank(schema, field) do quote do test \u0026#34;fails when given a blank :#{unquote(field)}\u0026#34; do schema = unquote(schema) field = unquote(field) {result, changeset} = schema |\u0026gt; get_factory |\u0026gt; params_for(%{field =\u0026gt; \u0026#34;\u0026#34;}) |\u0026gt; schema.insert assert result == :error assert changeset.errors == [{field, {\u0026#34;can\u0026#39;t be blank\u0026#34;, [validation: :required]}}] end end end end With the macro above, we can now do one-liners like these:\ndefmodule UserTest do use ExUnit.Case import TestHelper describe \u0026#34;insert/1\u0026#34; do #... test_insert_prevent_blank(User, :name) end end defmodule AccountTest do use ExUnit.Case import TestHelper describe \u0026#34;insert/1\u0026#34; do #... test_insert_prevent_blank(Account, :name) end end And it is very readable when combined with other similar test helpers:\ndefmodule UserTest do use ExUnit.Case import TestHelper describe \u0026#34;insert/1\u0026#34; do test_insert_generate_uuid(User, :uuid) test_insert_prevent_blank(User, :name) test_insert_prevent_blank(User, :email) test_insert_prevent_duplicate(User, :email) test_insert_generate_timestamps(User) # Other schema-specific tests... end end Conclusion We have been using this test-helper-as-a-macro approach in our project at omisego/ewallet with satisfaction. It has worked well so far with the following benefits:\n One-liner tests. Helps optimize valuable screen estate for browsing through the tests. Meanwhile the tests still have their explicity, not being hidden away behind some higher-level abstraction. Not having to worry about human-error applying a change to the test behavior across the codebase. Even the test names are reflected by the macro. When a test fails, its error pinpoints to the exact assertion. The error messages are very clear, and the test name represents the assertion exactly. We\u0026rsquo;re not hacking how ExUnit works, relying purely on ExUnit\u0026rsquo;s public API.  If you find this approach interesting, you can find real-world examples of the helper macros at EWalletDB.SchemaCase, and usage at EWalletDB.RoleTest.\nWhat do you think? Do you find any drawback or a better solution? Let me know!\n"},{"idx":14,"href":"/tags/testing/","title":"testing","content":""},{"idx":15,"href":"/10-business/2019-09-28-psychology-of-money/","title":"[Article Review] The Psychology of Money by Morgan Housel","content":" [Article Review] The Psychology of Money by Morgan Housel This article, The Psychology of Money, was recommended to me by Ino Murko. It\u0026rsquo;s a great read on personal investment.\nThe author described 20 flaws, biases, and causes of bad behavior when people deal with money. Below are my favorite excerpts.\n \u0026ldquo;In no other field does someone with no education, no relevant experience, no resources, and no connections vastly outperform someone with the best education, the most relevant experiences, the best resources and the best connections [\u0026hellip;] Managing money isn’t necessarily about what you know; it’s how you behave. [\u0026hellip;] The finance industry talks too much about what to do, and not enough about what happens in your head when you try to do it.\u0026rdquo;\n \u0026ldquo;An overreliance on past data as a signal to future conditions in a field where innovation and change is the lifeblood of progress. The cornerstone of economics is that things change over time, because the invisible hand hates anything staying too good or too bad indefinitely.\u0026rdquo;\n \u0026ldquo;The problem with viewing crowds as evidence of accuracy when dealing with money is that opportunity is almost always inversely correlated with popularity.\u0026rdquo;\n \u0026ldquo;The first rule of compounding is to never interrupt it unnecessarily.\u0026rdquo;\n \u0026rdquo; \u0026lsquo;Don’t do anything\u0026rsquo; are the most powerful words in finance. But they are both hard for individuals to accept and hard for professionals to charge a fee for.\u0026rdquo;\n \u0026ldquo;What you don’t realize is that the traders moving the marginal price are playing a totally different game than you are. And if you start taking cues from people playing a different game than you are, you are bound to be fooled and eventually become lost, since different games have different rules and different goals.\u0026rdquo;\n \u0026ldquo;Because finance is entertaining in a way other things – orthodontics, gardening, marine biology – are not. Money has competition, rules, upsets, wins, losses, heroes, villains, teams, and fans that makes it tantalizingly close to a sporting event. But [\u0026hellip;] you’re both the fan and the player, with outcomes affecting you both emotionally and directly. Which is dangerous.\u0026rdquo;\n \u0026ldquo;Extrapolating the recent past into the near future, and then overestimating the extent to which whatever you anticipate will happen in the near future will impact your future. Most of the time, something big happening doesn’t increase the odds of it happening again. It’s the opposite, as mean reversion is a merciless law of finance.\u0026rdquo;\n \u0026ldquo;If you see someone driving a $200,000 car, the only data point you have about their wealth is that they have $200,000 less than they did before they bought the car. [\u0026hellip;] Wealth, in fact, is what you don’t see. It’s the cars not purchased. The diamonds not bought. The renovations postponed, the clothes forgone and the first-class upgrade declined. It’s assets in the bank that haven’t yet been converted into the stuff you see.\u0026rdquo;\n  If you find these excerpts resonate with you, check out the original article: The Psychology of Money by Morgan Housel.\n"},{"idx":16,"href":"/tags/business/","title":"business","content":""},{"idx":17,"href":"/tags/finance/","title":"finance","content":""},{"idx":18,"href":"/80-life/2019-05-04-koom-koom-coffee/","title":"Koom Koom — Good coffee beans at affordable prices","content":" Koom Koom — Good coffee beans at affordable prices First, a bold disclaimer that I\u0026rsquo;m no coffee expert, but I do have a difficult time finding coffee beans that I like. My coffee preference gradually moved towards bolder drinks, i.e. I started drinking coffee with iced mocha, then cappucino, then finally settling down with espresso.\nSince I started drinking espresso, I noticed I\u0026rsquo;ve become more picky about the bean. I suppose it\u0026rsquo;s to do with espresso being pretty much concentrated coffee, not diluted in milk or anything other than a small amount of water. And buying a bag of coffee beans only to find out that I dislike it after a shot brings much sadness to life.\nRecently I was recommened by an OmiseGO colleague, Noei, to Koom-Koom. When I asked for a coffee bean that is very low to no acidity for espresso, the store person recommended Doi Saket, a 100% Arabica from Chiang Mai. I bought that bean and was not disappointed. It\u0026rsquo;s pretty much a mid-to-dark roast, a little sweet, and does not taste sour at all.\n  Koom Koom Coffee (Ikea clipper not included :p)   Koom-Koom calls itself a wholesale shop, so the minimum order is 1kg. The price is very affordable though and orders are shipped twice a week. Doi Saket costed me 330 Baht for a kilo, plus 95 Baht shipping (shipping cost is billed exactly as quoted by the shipping company), so no big deal. My order arrived within a week, just in time before my Starbucks beans ran out.\nIf you are looking for a coffee bean for your espresso, and you like it with little to no acidity, this may be worth trying. Head out to their online shop to order.\nKoom-Koom Coffee — online store only.\n"},{"idx":19,"href":"/tags/life/","title":"life","content":""},{"idx":20,"href":"/80-life/2019-04-22-phil-vienna/","title":"Phil — The best cafe in Vienna","content":" Phil — The best cafe in Vienna Despite so many cafes in Vienna, Phil, in my opinion, is the best one by far. I came here for a few hours of relax and work for both days of my stay in Vienna.\n  Phil\u0026#39;s atmosphere at night   Phil calls itself a coffee shop, a bar, a book store, a vintage furniture store (most if not all furnitures used in the shop are available for sale), a small movie shop (sells DVDs) and a small record shop (sells vinyl).\nIt is located only a 4-minute walk from Museumsquartier subway in a relatively quiet district, makes it really easy to access and quite peaceful.\nThe fact that it is open from 9AM - 1AM is also a big plus (although last order is around midnight). Looking for hungry and a place to read a book in the morning? Phil is open. Looking for a beer and some night-owl work? Phil is open.\nTheir food is also delicious and comforting. Here\u0026rsquo;s a photo of Phil Sandwhich which I dearly loved.\n  Phil Sandwich   If you have some time to spend in Vienna and looking for a cafe to sit and relax, I recommend trying Phil out.\nPhil — Gumpendorfer Str. 10 - 12, 1060 Wien, Austria (Google Maps)\n"},{"idx":21,"href":"/tags/blockchain/","title":"blockchain","content":""},{"idx":22,"href":"/tags/ethereum/","title":"ethereum","content":""},{"idx":23,"href":"/03-blockchain/2018-02-26-ethereum-casper-sharding-karl-floersch/","title":"สรุปทอล์ก Ethereum, Casper และ Sharding โดย Karl Floersch","content":" สรุปทอล์ก Ethereum, Casper และ Sharding โดย Karl Floersch Originally published at blog.omisego.network\n  เมื่อวานผมมีโอกาสไปร่วมงาน Asia-Pacific Ethereum Community Meetup ที่ตึก KX ของ ม.พระจอมเกล้าฯ บางมด ช่วงเช้ามีทอล์กของคุณ Karl Floersch ที่น่าจะเป็นทอล์กที่คนประทับใจมากที่สุดของวันนั้น(เคียงข้างทอล์กของ Vitalik Buterin) เลยอยากเขียนสรุปมาแบ่งปันให้เพื่อน ๆ ที่สนใจเกี่ยวกับพัฒนาการในอนาคตอันใกล้ของ Ethereum ครับ\nทอล์กของคุณ Karl Floersch แบ่งออกเป็น 3 ส่วน ซึ่งเป็น 3 องค์ประกอบหลักของ Ethereum ในอนาคตอันใกล้ ดังนี้:\n Ethereum Casper Sharding    Part 1: Ethereum  คนส่วนใหญ่ถ้าเคยได้ยินคำว่า Ethereum น่าจะเข้าใจว่ามันคือคอมพิวเตอร์ที่ร่วมกันประมวลผลทั่วโลก (World’s computer) หรือแพลตฟอร์มสำหรับทำ ICO แต่จริง ๆ แล้วมีคำนิยาม Ethereum ที่ดีกว่านั้น คุณ Karl กล่าวถึงเหตุการณ์แบล็คสวอน (Black Swan) หรือเหตุการณ์ร้ายแรงที่มีผลกระทบต่อระบบหรือองค์กรอย่างสิ้นเชิง แต่โอกาสที่จะเกิดขึ้นนั้นมีน้อยมาก ๆ เหมือนการค้นพบห่านที่มีสีดำ โดยมีอยู่ 3 เหตุการณ์ที่เป็นชนวนให้เกิด Ethereum ขึ้น: Black Swan 1: วิกฤตแฮมเบอร์เกอร์เมื่อปี 2008 ที่สถาบันการเงินในอเมริกาล้มลงเนื่องจากหนี้เสียจำนวนมาก จนรัฐบาลต้องออกมาอุ้มแต่นายแบงก์ก็ลอยนวลไปด้วยกำไรมหาศาล โดยที่เรามองไม่เห็นว่าพวกเขาทำอะไรกันอยู่ ไม่รู้ว่าเขาบริหารเงินของเราอย่างไร และเราไม่มีสิทธิ์เรียกร้องใด ๆ ทั้งสิ้น ทำให้ประชาชนจำนวนมากหมดศรัทธากับระบบการเงินแบบศูนย์กลาง Black Swan 2: Vitalik Buterin ผู้ร่วมก่อตั้ง Ethereum ผู้ชื่นชอบเล่น Warlock (Lvl. 60) ใน Word of Warcraft วันหนึ่งเจ้าของเกมอยู่ดี ๆ ก็ประกาศยกเลิกตัว Warlock ที่เขาเล่น เป็นการตอกย้ำถึงความย่ำแย่ของการบริหารแบบใช้ศูนย์กลาง (อันนี้เป็นตัวอย่างขำ ๆ) Black Swan 3: Twitter อยู่ดี ๆ ก็ปิด API ตนเอง ไม่ให้นักพัฒนาที่ทำแอพเชื่อมต่อกับทวิตเตอร์ดึงข้อมูลได้ ทำให้หลาย ๆ แอพที่ถูกใช้อย่างกว้างขวางต้องปิดตัวลงอย่างถาวร Ethereum จึงถูกสร้างขึ้นเพื่อให้เป็นระบบที่ทุกคนสามารถมีส่วนร่วม และตรวจสอบการทำงานภายในของมันได้ สามารถเชื่อใจในตัวระบบได้ว่าโค้ดที่เราเห็น ไม่ว่าจะเป็นโค้ดที่ใช้ส่งเหรียญ ETH ไปมา หรือ Smart Contract ต่าง ๆ จะถูกรันตามนั้นจริง ๆ และไม่มีใครมีสิทธิ์ที่จะล้มล้างกฎเกณฑ์ที่เขียนไว้ในโค้ดได้ (Vitalik เลือกที่จะไม่ต่อยอดจาก Bitcoin เนื่องจากปัญหาเสถียรภาพของทีม Bitcoin) ทีม Ethereum เชื่อว่า การที่จะลดจำนวนเหตุการณ์แบล็คสวอนได้นั้นอยู่ที่การขีดเส้นขอบเขตอำนาจนั้นอย่างชัดเจน และทำให้เส้นอำนาจนั้นสามารถถูกตรวจสอบได้โดยคนจำนวนมาก ICO และ Cryptokitties พิสูจน์ให้เห็นว่าเราสามารถใช้ เศรษฐศาสตร์คริปโต (cryptoeconomics) ในการสร้างความเชื่อใจกันระหว่างคนที่ไม่รู้จักกันได้ แต่ 2 สิ่งนั้นเป็นเพียงก้าวแรกที่น่าเบื่อเท่านั้น (boring first steps) คุณ Karl จึงนิยาม Ethereum ว่าเป็นแพลตฟอร์มสำหรับการประมวลผลทั่วไปที่สร้างสภาพแวดล้อมที่เอื้อต่อการบังคับใช้สัญญาอิเล็กทรอนิกส์ โดยที่เราสามารถเชื่อใจได้ว่าข้อสัญญาที่เขียนขึ้นด้วยโค้ดนั้นจะถูกบังคับใช้อย่างถูกต้อง    Part 2: Casper  ปัญหาของ Proof of Work: หลาย ๆ คนที่ติดตามข่าวสารบล็อกเชนน่าจะทราบกันดีว่าหนึ่งในข้อด้อยของบล็อกเชนในปัจจุบันคือการที่เหล่า validators (ผู้ตรวจสอบธุรกรรม) ต้องใช้พลังงานปริมาณมหาศาลเพื่อแข่งกันคำนวณโจทย์ทางคณิตศาสตร์ ใครที่ตอบโจทย์ได้เป็นคนแรก คนนั้นจะได้ค่าธรรมเนียมธุรกรรมนั้นไป (Proof of Work) ทำให้ทุกคนมีต้นทุนในการร่วมวง และมีความเสี่ยงในการเสียต้นทุน(ค่าไฟ)นั้นไป หากพยายามเล่นตุกติกกับระบบแล้วคนอื่นจับได้ Proof of Stake คือคำตอบ: ในระบบ Proof of Stake (ภายใต้โค้ดเนม Casper) แทนที่ validators จะแข่งกันโดยการผลาญไฟฟ้า ลอจิคของ Casper จะให้ validator วางเดิมพัน/มัดจำ เช่น ETH เพื่อเป็นคำสัญญาว่าจะประพฤติดี แล้วตัว Casper จะสุ่ม validator ขึ้นมาจำนวนหนึ่งเพื่อทำการโหวต หากมีการพยายามโกงโหวตเกิดขึ้นและ validator ถูกโหวตออก แทนที่คนโกงจะเสียค่าไฟฟ้าที่ใช้ในการคำนวณ (ซึ่งมีผลกระทบทางธรรมชาติ และทำให้ราคาไฟฟ้าสูงขึ้นสำหรับทุกคน) ก็จะเสีย ETH ที่วางเดิมพันไว้แทน ซึ่งเป็นวิธีการที่ Ethereum ได้เลือกที่จะใช้เพื่อเป็นแรงจูงใจให้คนประพฤติดีโดยไม่เสียทรัพยากรโลกโดยใช่เหตุ    สเต็ปปกติในการโหวตบน Casper   ซึ่งการ validate ด้วย Proof of Stake ก็มีปัญหาของมันเอง หลัก ๆ คือ Double Vote และ Surround Vote:\n  เดิมพันจะถูกหักจากคนที่พยายามจะโหวตหลายบล็อกพร้อมกัน   ส่วน Surround Vote นั้น คุณ Karl ข้ามไป จึงไม่แน่ใจว่าจริง ๆ แล้วมันทำงานยังไง (อ้าว งงด้วยคน)\n  เดิมพันจะถูกหักจากคนที่เคยโหวตบล็อกหนึ่งไปแล้ว แต่บล็อกต่อมาขัดแย้งกับที่เคยโหวตไป   เมื่อนำทั้งการป้องกัน double vote และ surround vote มารวมกัน ก็จะเห็นภาพบล็อกทุจริตที่ถูกตีตกตามภาพด้านล่างนี้\n  ตัวอย่างการโจมตีที่ล้มเหลวถึงแม้ height ของผู้โจมตีจะอยู่สูงกว่า เพราะบล็อกปลอมจะเข้าข่าย slashing conditions   Part 3: Sharding  คุณ Karl กล่าวว่า Sharding คือสปอตไลต์ของบล็อกเชนในปี 2018 เพราะปัจจุบันบล็อกเชนมีปัญหาด้าน scalability อย่างมาก ในความเป็นจริง เราสามารถสเกลบล็อกเชนได้การใช้บล็อกที่ใหญ่ขึ้น ใช้คอมพิวเตอร์ที่แรงขึ้น แต่จุดประสงค์ของ decentralized network คือการทำให้ทุกคนบนโลกสามารถมีส่วนร่วมในระบบนี้ได้ การสเกลด้วยคอมพิวเตอร์ที่ใหญ่ขึ้นนั่นหมายถึงการทำให้คนจำนวนน้อยลงสามารถมีส่วนร่วมกับระบบได้ ซึ่งไม่ตอบโจทย์การทำ decentralized network อย่างแน่นอน Sharding ในเฟสแรกจะมี 100 shards (แบ่งข้อมูลทั้งหมดออกเป็น 100 ส่วน) Validators ของแต่ละ shard จะถูกสุ่มขึ้นมาล่วงหน้า 5 บล็อกเพื่อให้เวลาดาว์นโหลดข้อมูลล่าสุดของ shard ที่ต้องตรวจสอบ Validators ของแต่ละ shard จะสร้าง collation header ซึ่งเป็นเหมือน block header ไว้เก็บข้อมูลสรุปของ shard นั้น ๆ แล้วส่งไปเก็บรักษาที่ root chain อีกที ทีม Ethereum เชื่อว่า ด้วยโปรเจกต์ที่กำลังดำเนินการอยู่ ทั้ง Casper, Sharding, Plasma และการออกแบบเศรษฐศาสตร์คริปโต จะทำให้เกิดแอพพลิเคชั่นที่ไม่มีศูนย์กลางและสเกลได้อย่างกว้างขวางเกิดขึ้นได้จริงๆ ตัว Sharding เองพลิกแพลงได้ไม่มาก แต่อีกส่วนหนึ่งที่จะทำให้การสเกลเกิดขึ้นได้จริงคือการให้ความรู้กับผู้ที่เขียน smart contract เพราะเทรนด์ตอนนี้คือการเขียน smart contract ที่ใหญ่สโคปขึ้นเรื่อย ๆ ซึ่งไม่จำเป็น เช่น เราต้องการสร้างระบบจัดเก็บรูปที่บิดเบือนไม่ได้ เราไม่จำเป็นต้องเซฟรูปไว้บนบล็อกเชน เราจะใส่เฉพาะ hash ของรูปนั้นแล้วเก็บข้อมูลไฟล์ไว้ที่ AWS ก็ยังได้ หรือจริง ๆ แล้วการเซฟรูปไว้ที่อื่น hash รูปทั้งหมดเข้าด้วยกัน และบันทึกเพียง hash เดียวไว้บนบล็อกเชนก็ยังได้เลย    ตัวอย่างการทำงานของ Sharding   Q\u0026amp;A ในช่วง Q\u0026amp;A คุณ Karl ได้ตอบคำถามที่ผมคิดว่าน่าสนใจอยู่ 2 คำถาม นั่นคือ\nQ: คุณคิดว่าจะมีเหตุการณ์ hard fork เพื่อแก้ไขการถูกแฮกอย่างที่เกิดขึ้นกับ DAO เมื่อปีที่แล้ว (2016) ที่กู้คืนเงินกว่าพันล้านบาทคืนอีกหรือไม่? A: ผมคิดว่าจะไม่มีเหตุการณ์ hard fork เพื่อแก้ไขการถูกแฮกเกิดขี้นอีก เพราะ ณ วันนี้เรามีผู้ร่วมในระบบเราเยอะขึ้นมาก ๆ ซึ่งแปลว่าการตกลงทำ hard fork เพื่อเหตุการณ์แบบนี้จะเกิดขึ้นยากขึ้นเรื่อย ๆ ซึ่งเป็นเรื่องดีเพราะแปลว่าระบบจะมีความแน่นอนมากยิ่งขึ้น\nQ: อะไรคือแรงที่ทำให้คุณหันมาสร้าง Ethereum ซึ่งเป็นกิจกรรมที่แตกต่างไปจากวัยรุ่นทั่วไปทำมาก ๆ ? (คุณ Karl เพิ่งอายุ 24 ในวันที่เขาขึ้นพูดเมื่อวาน) A: ผมคิดว่ามนุษยชาติของเรากำลังไปได้ค่อนข้างดีนะ แต่อินเทอร์เน็ตเองก็สร้างความท้าทายใหม่ ๆ ขึ้นมามากมายให้เราต้องจัดการ ยิ่งนับวันเรายิ่งเห็นองค์กรจำนวนน้อยลงแต่องค์กรเหล่านี้ผูกขาดอินเทอร์เน็ตมากขึ้นและมีอำนาจอย่างมหาศาล ในขณะที่เราก็กำลังย้ายชีวิตของเราขึ้นไปอยู่บนโลกออนไลน์มากขึ้น มันจึงสำคัญมากที่เราจะต้องทำให้อินเทอร์เน็ตเป็นพื้นที่เปิด และเป็นเจ้าของร่วมกันโดยทุกคน ไม่ใช่มีคนไม่กี่คนที่สามารถบังคับสวิตช์ได้ตามใจชอบ และถึงแม้เราจะขีดเส้นกำกับอำนาจศูนย์กลางได้ แต่ถ้าคนดูแลเส้นนั้นมีแต่คนที่อยู่ในซิลิคอนวัลเลย์ เราก็จะได้อำนาจแบบซิลิคอนวัลเลย์ มันจึงจำเป็นมากที่เราจะต้องทำให้อำนาจนี้กระจายออกไปให้ได้มากที่สุด ให้ทุกคนบนโลกได้เป็นเจ้าของระบบนี้ไปด้วยกัน\nอ้างอิง: https://youtu.be/jpmaMMAUDU0?t=1h2m55s\n"},{"idx":24,"href":"/01-software-development/2016-12-19-laravel-config/","title":"Don’t use Laravel’s config() inside config files","content":" Don’t use Laravel’s config() inside config files Originally published at blog.maqe.com\na.k.a. Underlying OS behavior can impact your web application’s behavior.\nUpdate: As of 2017–10–12, config file loading in Laravel 5.5 is now ordered by file names. See the pull request [5.5] Ensure config load order across multiple installations.\n A code excerpt from Laravel’s Illuminate\\Foundation\\Bootstrap\\LoadConfiguration   Last week we were working on implementing a feature for a Laravel project running on load-balanced EC2 instances. The feature that we built required two configuration values which normally would reside happily within a file or two in the config/ folder.\nHowever, this time our team tried something a bit differently. We had a config that references another config in another file, like this:\nconfig/a.php:\n\u0026lt;?php return [ \u0026#39;a_value\u0026#39; =\u0026gt; \u0026#39;my_config_value\u0026#39;, ];  config/b.php:\n\u0026lt;?php return [ \u0026#39;b_value\u0026#39; =\u0026gt; config(\u0026#39;a.a_value\u0026#39;), ];  What happened? Once we deployed the code to our test environment, we noticed one strange behavior. One instance was able to lookup the config values successfully. However, the other returned null.\nInstance 1:\n$ php artisan tinker \u0026gt;\u0026gt;\u0026gt; config(\u0026#39;a.a_value\u0026#39;); =\u0026gt; \u0026#34;my_config_value\u0026#34; \u0026gt;\u0026gt;\u0026gt; config(\u0026#39;b.b_value\u0026#39;); =\u0026gt; \u0026#34;my_config_value\u0026#34; Instance 2:\n$ php artisan tinker \u0026gt;\u0026gt;\u0026gt; config(\u0026#39;a.a_value\u0026#39;); =\u0026gt; \u0026#34;my_config_value\u0026#34; \u0026gt;\u0026gt;\u0026gt; config(\u0026#39;b.b_value\u0026#39;); =\u0026gt; null We checked deployment logs and file content on both servers. The code was deployed successfully with identical instructions, and the files were identical. Basically everything looked identical on two instances but the results were different!\nThe solution After tinkering with config(), it turned out that using config() outside config files seemed to work fine. Only using Laravel’s config() in another config file that does not always yield the correct value. Hence, never use Laravel’s config() in config files.\nAlthough it was tempting to stop the investigation just there, we knew we could do more…\nThe search for enlightenment We made our servers provisioning and code deployment fully scripted and automated just so that we would avoid problems like this! Two instances that produce different results defeats the whole purpose of having a fully automated workflow.\nThe root cause must be found.\nSince the server instances were more or less identical, we believed we could trace the code back far enough to find the point where the code’s output starts to diverge. It must be working identically up to some point, and right after that point should be the key to the root cause. So here is the journey down that road.\nHow config() gets its values? During bootstrap, Laravel does the following:\n Creates a Illuminate\\Config\\Repository class as storage for all config values. Load all configuration files, loop all configuration files and put all the configs found into the Repository above. When a code calls config(), it retrieves value by calling Repository::get(). Laravel simply returns the value that has already been loaded during bootstrap.  But really, how config() gets its values? So now we know that all config values are already loaded from their files right at bootstrap. We dig further to see how that works in Laravel’s src/Illuminate/Foundation/LoadConfiguration.php:\nIn LoadConfiguration.php, it loops through each configuration file one by one:\n\u0026lt;?php protected function loadConfigurationFiles(...) { foreach ($this-\u0026gt;getConfigurationFiles($app) as $key =\u0026gt; $path) { $repository-\u0026gt;set($key, require $path); } }  The code above gets the file list from getConfigurationFiles():\n\u0026lt;?php use Symfony\\Component\\Finder\\Finder; ... protected function getConfigurationFiles(Application $app) { ... foreach (Finder::create()-\u0026gt;files()-\u0026gt;name(\u0026#39;*.php\u0026#39;)-\u0026gt;in($configPath) as $file) { ... } }  The code above uses Symfony’s Symfony\\Component\\Finder\\Finder to get the file list. And so we wrote some tinker code to see if the two server instances produce the same result:\n$ php artisan tinker use Symfony\\Component\\Finder\\Finder; foreach (Finder::create()-\u0026gt;files()-\u0026gt;name(\u0026#39;*.php\u0026#39;)-\u0026gt;in(\u0026#39;config/\u0026#39;) as $file) { echo $file-\u0026gt;getFilename(); } Result — Instance 1:\n\u0026#34;session.php\u0026#34; \u0026#34;domains.php\u0026#34; \u0026#34;urls.php\u0026#34; \u0026#34;auth.php\u0026#34; \u0026#34;app.php\u0026#34; Result — Instance 2:\n\u0026#34;urls.php\u0026#34; \u0026#34;auth.php\u0026#34; \u0026#34;domains.php\u0026#34; \u0026#34;session.php\u0026#34; \u0026#34;app.php\u0026#34; Dumping the returns from Finder above, we see dissimilar results for the two server instances. Digging down even further reveals that Symfony uses PHP’s RecursiveDirectoryIterator. This behavior was reported and concluded in RecursiveDirectoryIterator output is not sorted as follow:\n The manual does not guarantee anything about the order.\nRecursiveDirectoryIterator (and the other filesystem based iterators) iterate in the order the OS returns the files to them.\nThat it is sorted on Windows is not guaranteed by PHP, it just seems to happen due to the underlying implementation in the Windows kernel.\n By investigating further, we found the inode numbers of the config files that confirms this:\nInstance 1:\n$ ls -i1 config/ | sort -n 309925 session.php 309926 domains.php 309932 urls.php 309940 auth.php 309941 app.php Instance 2:\n$ ls -i1 config/ | sort -n 324900 urls.php 324905 auth.php 324906 domains.php 324914 session.php 324915 app.php The files sorted by inode numbers exactly matched the sequence that RecursiveDirectoryIterator returned. This means that on Instance 1, urls.php is be able to see configurations from domains.php, but Instance 2 does not, which exactly matches the behavior we found at the beginning.\nLessons learnt:  As a Laravel’er: Don’t use Laravel’s config() inside config files. The file system may produce varying results on different machines and/or operating systems. As a coder: Don’t assume your system will behave consistently just because you have identical code. If you expect a behavior, be explicit about it. If you need files sorted by file names, then explicitly sort them, don’t assume just because ls or your IDE tells you so. As a DevOps/QA: This proves how important it is to have a test environment that mimics production environment as close as possible. You can’t call your web applications scalable if your testing does not involve an comparably scalable test environment.  This writing is the result of effort put in by a team at MAQE Bangkok Co., Ltd. consisting of Siravit “Arm” Praditkul, Atthaphon “Jo” Urairat, Wanida “Gift” Sittipanya and Panupong “Big” Sritananun.\nBonus point: What’s an inode? An inode contains essentially information about ownership (user, group), access mode (read, write, execute permissions) and file type of a file.\n"},{"idx":25,"href":"/tags/laravel/","title":"laravel","content":""},{"idx":26,"href":"/tags/php/","title":"php","content":""},{"idx":27,"href":"/01-software-development/2016-12-19-code-with-money-pattern/","title":"ให้เงินทำงานด้วย Money Pattern","content":" ให้เงินทำงานด้วย Money Pattern เผยแพร่ครั้งแรกที่ blog.maqe.com\n  \u0026ldquo;เอ้า ตังค์ทอน 100 บาท มากัน 3 คน … ฉีกแบงค์กันไปคนละส่วนแล้วกัน\u0026rdquo;\n ประโยคนี้น่าจะถูกใช้เป็นมุกบนโต๊ะอาหารอยู่บ่อย ๆ แต่ถ้าเหตุการณ์นี้เกิดขึ้นในระบบที่เราต้องให้ความมั่นใจผู้ใช้งานได้ ว่าเงินทุกบาททุกสตางค์ถูกคำนวนมาอย่างถูกต้อง เที่ยงตรง ไม่มีการมุมมิบ เราจะยังขำกันได้อยู่หรือเปล่า?\nในยุคที่การให้เหรียญสลึง = แช่ง การคำนวนเศษในหลักสตางค์ก็คงเป็นเรื่องที่ไม่สำคัญนัก หากแต่ในระบบที่มีคนใช้เป็นหมื่นเป็นแสนคน มีการทำรายการนับครั้งไม่ถ้วนต่อวัน ปัญหาของเศษเสี้ยวสตางค์จะกลายเป็นปัญหาระดับร้อยล้านพันล้านไปในทันที ค่าที่ผิดไปเพียง 0.01 บาทจาก 1 แสนรายการต่อวัน คิดเป็นเงินกว่า 350,000 บาทต่อปี เงินจำนวนนี้ไปตกอยู่ที่ไหน เราสามารถปล่อยให้มันหายไปในอากาศได้หรือเปล่า?\nถ้าคำตอบคือจะยอมให้หายไปไม่ได้ … Money Pattern (หรือ Money Object, Money Value ฯลฯ) จึงเป็นหนึ่งใน Design Pattern ที่ควรพกติดตัวไว้ เพราะในสมัยนี้ คงระบบที่จะไม่ได้ยุ่งกับจำนวนเงินเลยน้อยลงเรื่อย ๆ ทุกวัน\nและถึงแม้ว่าเราจะไม่มีโอกาสได้ทำงานกับจำนวนเงินเลย ปัญหานี้ก็เป็นตัวอย่างเตือนสติได้อย่างดี ว่าการทำงานกับระบบคอมพิวเตอร์และการเขียนลอจิคให้ครอบคลุมการใช้งานของมนุษย์นั้น มันไม่ได้ง่ายเหมือนจิ้มเครื่องคิดเลขบวกลบคูณหารทีเดียวจบเสมอไป\nปัญหาของการเขียนโค้ดกับจำนวนเงิน ปัญหาที่ 1: การแบ่งเงินเป็นกองๆ … มีเศษที่หายไป มีเงินอยู่ 10,000 บาท จะแบ่งฝากเข้าบัญชี 3 บัญชีเท่า ๆ กัน (บัญชีเงินลงทุน, บัญชีเงินเก็บไปเที่ยว, บัญชีเงินค่าขนม) จะต้องฝากบัญชีละเท่าไหร่?\nคำตอบก็คือเอา 10,000 หาร 3 แล้วโอนเข้าไป? นี่คือคำตอบที่… ผิด\nมันไม่ได้ง่ายอย่างนั้น เพราะ 10,000 / 3 = 3,333.3333333 เป็นเลขที่หารไม่ลงตัว และการตัดเหลือ 3,333.33 บาท ก็จะทำให้ผลรวมขาดไป 0.01 บาท เงินจำนวนนี้จะไม่มีที่ลงไม่ได้\nปัญหาที่ 2: สกุลเงินต่างกัน … จะนำมาคำนวนกันโดยตรงไม่ได้ 100 USD + 100 THB จะต้องใช้อัตราแลกเปลี่ยนอะไร? ผลลัพธ์จะต้องเป็น USD หรือ THB? คำถามนี้ให้เห็นว่า 100 USD + 100 THB ต้องมีข้อมูลมากกว่าแค่จำนวนเงินสองตัวในการคำนวน\nเราจะการันตีได้อย่างไรว่าเราได้ป้องกันไม่ให้เกิดการคำนวนเงินข้ามสกุลเงินตรง ๆ ไว้แล้ว? และการต้องเขียนโค้ดให้ดักสกุลเงินทุกรอบที่มีการคำนวน ใช่คำตอบที่ดีที่สุดหรือเปล่า?\nปัญหาที่ 3: คอมพิวเตอร์มองจุดทศนิยมไม่เหมือนมนุษย์ ลองเปิด Developer Console แล้วลองเลย…\n\u0026gt; 0.10 + 0.20 == 0.30 \u0026gt; false  เนื่องจากคอมพิวเตอร์เก็บเลขทศนิยมเป็น float มันจึงไม่สามารถเก็บและคำนวนได้อย่างแม่นยำเสมอไป (ชาว stackoverflow มีอธิบายไว้อย่างละเอียด) ซึ่งยิ่งมีการผลลัพธ์ไปคำนวนต่อมากเท่าไหร่ ก็จะยิ่งทำให้จำนวนเงินบิดเบือนไปจากจำนวนที่ควรจะเป็นมากขึ้นเรื่อยๆ\nและที่สำคัญที่สุดก็คือ ปัญหานี้ไม่ได้ขึ้นอยู่กับภาษาโปรแกรมมิ่งภาษาใดภาษาหนึ่ง แต่เป็นปัญหาพื้นฐานที่จะเกิดขึ้นตราบใดที่เรายังคงต้องใช้คอมพิวเตอร์ในการทำงานกับจำนวนเงิน และ/หรือเลขทศนิยม\n  คำตอบ: Money Pattern ช่วยคุณได้ Money Pattern เป็น Design Pattern สำหรับเก็บและทำงานกับจำนวนเงินในโค้ด ซึ่งถูกนิยามไว้ในหนังสือ Patterns of Enterprise Application Architecture โดย Martin Fowler โดยเขากล่าวถึงปัญหาไว้ว่า\n Once you involve multiple currencies you want to avoid adding your dollars to your yen without taking the currency differences into account.\nThe more subtle problem is with rounding. Monetary calculations are often rounded to the smallest currency unit. When you do this it\u0026rsquo;s easy to lose pennies (or your local equivalent) because of rounding errors.\nThe good thing about object-oriented programming is that you can fix these problems by creating a Money class that handles them.\n เนื่องจากผมได้เข้าไป contribute ในโปรเจกต์นี้อยู่บ้าง จึงขอยก moneyphp/money มาเป็นตัวอย่าง…\nแนวทางคร่าว ๆ ก็คือ การจับจำนวนเงินทั้งหมดให้อยู่ในรูปแบบ Money objects แล้วทำงานกับ objects เหล่านี้ แทนที่จะทำงานกับตัวเลขโดยตรง เช่น\n\u0026lt;?php $cash = Money::THB(100); // ฿1.00  ตัว Money object จะมีตัวช่วยหลาย ๆ อย่างที่ทำให้การทำงานสะดวกยิ่งขึ้น เช่น add(), subtract(), allocateTo(), equals(), greaterThan() ฯลฯ ที่จะช่วยให้เราจัดการกับปัญหาที่กล่าวถึงก่อนหน้านี้ได้ง่ายขึ้นมาก ๆ\nข้อควรระวัง: เนื่องจากการส่งค่าจุดทศนิยมมีโอกาสทำให้ค่าที่รับเข้าไปผิดตั้งแต่แรก (garbage in, garbage out) การใช้ Money pattern จึงยึดค่าโดยใช้หน่วยเล็กที่สุดของสกุลเงินนั้นเสมอ เช่น 1 บาทก็ต้องใส่ Money::THB(100)\nปัญหาที่ 1: การแบ่งเงินเป็นกองๆ … มีเศษที่หายไป ใช้ allocateTo() ในการแบ่งเงินออกเป็นกอง ๆ จำนวนเท่า ๆ กัน เศษของเงินจะถูกกระจายออกให้ได้มากที่สุด ทำให้ผลรวมของการแบ่งเท่ากับจำนวนเงินตั้งต้น เช่น\n\u0026lt;?php $profit = Money::THB(1000000); // ฿10000.00 $profit-\u0026gt;allocateTo(3); // [฿3333.34, ฿3333.33, ฿3333.33]  การแบ่งเงินออกเป็นหลาย ๆ สัดส่วนด้วย allocate():\n\u0026lt;?php $profit = Money::THB(500); // ฿5.00 $profit-\u0026gt;allocate([70, 30]); // [฿4.00, ฿1.00]  การเรียงสัดส่วนไม่เหมือนกันก็มีผลต่อการแบ่ง:\n\u0026lt;?php $profit = Money::THB(500); // ฿5.00 $profit-\u0026gt;allocate([30, 70]); // [฿2.00, ฿3.00]  ปัญหาที่ 2: สกุลเงินต่างกัน … จะนำมาคำนวนกันโดยตรงไม่ได้ เช็คสกุลเงินก่อนทำการคำนวน เพื่อป้องกันไม่ให้มีการคำนวนข้ามสกุลเงินโดยไม่ตั้งใจ:\n\u0026lt;?php $cashTHB = Money::THB(1000); // ฿1.00 $cashUSD = Money::USD(1000); // $1.00  $cashTHB-\u0026gt;add($cashUSD); // Exception  ปัญหาที่ 3: คอมพิวเตอร์มองจุดทศนิยมไม่เหมือนมนุษย์ ผู้พัฒนา Money object แต่ละตัวจะเลือกเก็บจำนวนเงินโดยไม่ใช้ float หรือ double เพื่อหลีกเลี่ยงปัญหาในการคำนวนกับ floating points ตัวอย่างที่เกิดขึ้นใน Developer Tool ด้านบนก็จะไม่เกิดขึ้นเมื่อใช้ Money object\n\u0026lt;?php $myCash = Money::THB(1); // ฿0.01 $yourCash = Money::THB(2); // ฿0.02  $ourCash = $myCash-\u0026gt;add($yourCash); // ฿0.03  ข้อควรระวังในการใช้ Money object  Money object จะรับค่าเป็นหน่วยย่อยที่สุด เช่น Money::THB(100) = 1 บาท (100 สตางค์) ไม่ใช่ 100 บาท Money object เป็น immutable object เสมอ เช่น  \u0026lt;?php $original = Money::THB(10000) // ฿100.00 $discount = Money::THB(1000) // ฿10.00  $salePrice = $original-\u0026gt;subtract($discount) // ฿90.00 $originalPrice // ฿100.00  หากไม่ได้เขียนโค้ดมาครอบคลุมพอ การเรียก $originalPrice-\u0026gt;subtract() จะทำให้ $originalPriceเปลี่ยนไปด้วย​ ซึ่งสิ่งที่ควรเปลี่ยนคือ $salePrice ไม่ใช่ $originalPrice\nMoney Pattern ในภาษาต่าง ๆ  PHP: https://github.com/moneyphp/money Ruby: https://github.com/RubyMoney/money Python: https://code.google.com/archive/p/python-money Javascript: https://github.com/openexchangerates/money.js Go: https://github.com/leekchan/accounting Swift: https://github.com/danthorpe/Money Java: https://github.com/JavaMoney/  แน่นอนว่า Money Pattern ไม่ใช่ silver bullet ที่สามารถการันตีได้ว่านักพัฒนาจะไม่ต้องสนใจการทำงานกับจำนวนเงินอีกเลย แต่การใช้ Money Pattern ก็ช่วยให้เราควบคุมพฤติกรรมของการคำนวนได้ดีขึ้น โดยเป็นการบังคับให้โค้ดที่ทำงานกับเงินจะต้องทำผ่านฟังค์ชั่นที่เรากำหนดไว้ มีพฤติกรรมที่ชัดเจน และเมื่อมีการทำงานที่ต้องห้าม ระบบก็จะสามารถฟ้องเราได้ทันที\nรู้อย่างนี้แล้ว พร้อมให้เงินทำงาน (ไปกับโค้ดของเรา) แล้วหรือยัง?\nบทความนี้เป็นประสบการณ์ส่วนหนึ่งจากการร่วมโปรเจกต์กับพี่หมี aimakun ที่บริษัท MAQE Bangkok\nปล.1 อ่านเพิ่มเติม ทำไมเราไม่ควรใช้ float หรือ double ในการเก็บจำนวนเงิน Why not use Double or Float to represent currency?\nปล.2 อ่านเวอร์ชั่นยาวและละเอียดยิบได้ที่ What Every Computer Scientist Should Know About Floating-Point Arithmetic\nปล.3 ใน PHP ยังใช้เครื่องหมายบวกลบคูณหารกับ money object แบบ Ruby ไม่ได้ ต้องใช้ -\u0026gt;add(), -\u0026gt;subtract() ฯลฯ ? รอหน่อยพี่ operator overloading ยังไม่มา\nปล.4 อ่านการพิสูจน์ทางคณิตศาสตร์ของ money allocation ได้ที่ Proof that Fowler\u0026rsquo;s money allocation algorithm is correct\n"},{"idx":28,"href":"/01-software-development/2016-09-30-load-testing-with-jmeter/","title":"Load Testing ด้วย Apache JMeter","content":" Load Testing ด้วย Apache JMeter เผยแพร่ครั้งแรกที่ blog.maqe.com\nเมื่อช่วงต้นปีที่แล้ว เว็บไซต์ที่บริษัทดูแลอยู่เกิด user surge ขึ้นเป็นช่วงระยะเวลาสั้นๆ ประมาณ 2 สัปดาห์ ถึงแม้ว่าเหตุการณ์จะจบลงอย่างน่าพอใจ สิ่งที่เกิดขึ้นทำให้ทีมต้องกลับมานั่งคิดขยับขยาย infrastructure ที่มีอยู่พอสมควร\nแต่ในระหว่างที่วางแผนการสเกลก็มีคำถามเกิดขึ้น เราจะรู้ได้อย่างไรว่าระบบที่เราสเกลออกด้วยจำนวน web server ที่มากขึ้นและ database server ที่ทรงพลังขึ้นจะรับโหลดได้มากขึ้นเท่าไหร่ และที่สำคัญคือเราจะต้องสเกลขึ้นเท่าไหร่จึงจะพอ?\nในบทความนี้จะไม่พูดถึงการคาดการณ์จำนวนผู้ใช้งานในอนาคต ซึ่งเป็นมุมมองฝั่ง business ที่เราไม่ได้ข้อมูลที่แน่นอนมาทำ load testing ในครั้งนั้น จุดประสงค์ของการ load testing ที่เกิดขึ้นจึงเป็นการวัดจำนวนผู้ใช้งานที่ระบบสามารถรองรับได้ด้วย configration ที่แตกต่างกัน เพื่อให้ทาง business สามารถพิจารณาได้ว่ามันเพียงพอสำหรับเขาไหม มีคำตอบให้ทีมสำหรับการสเกลที่อาจเกิดขึ้นในอนาคต และมีหลักฐานยืนยันว่าระบบสามารถรองรับการใช้งานในระดับที่กล่าวถึงได้จริง\n คำนิยาม คำจำกัดความของ load testing, performance testing, stress testing ฯลฯ นั้นแตกต่างกันไปตามลักษณะการทำงานของแต่ละบริษัท แต่เพื่อความเข้าใจที่ตรงกัน ในบทความนี้จึงขอนิยามไว้ 2 คำคือ performance testing และ load testing ไว้ดังนี้\nPerformance testing\n “… general testing performed to determine how a system performs in terms of responsiveness and stability under a particular workload.”\n“… การทดสอบใดๆ ที่วัดการตอบสนองและความเสถียร ภายใต้ปริมาณการใช้งานที่กำหนดไว้”\n Load Testing\n “… the process of putting demand on a system or device and measuring its response.”\n“… การทดสอบระบบด้วยการสร้างปริมาณการใช้งานเข้าไปและวัดการตอบสนองของระบบ”\n บางท่านอาจสงสัยว่า อ้าว แล้วสุดท้าย load testing มันต่างจาก performance testing อย่างไร ในที่นี้จะมองว่า performance testing คือบังเหียนใหญ่ที่มี load testing และวิธีทดสอบอื่นๆ อยู่ภายใต้ เช่น\n Soak testing (ระบบสามารถรองรับโหลดเป็นระยะเวลานานๆ ได้ไหม) Stress testing (ระบบรองรับโหลดที่มากเกินคาดการณ์ได้สูงสุดเท่าไหร่ก่อนที่ระบบจะล่ม หรือล่มแล้วสามารถกลับมาอยู่ในสภาพพร้อมทำงานใหม่ได้หรือไม่) ฯลฯ  ซึ่งทั้งหมดเป็นส่วนหนึ่งของการทำ performance testing\nการหาโจทย์สำคัญไม่น้อยไปกว่าการหาคำตอบ คำนิยามและการทำ performance testing นั้นมีหลายรูปแบบ และการทดสอบแต่ละรูปแบบก็จะให้คำตอบที่แตกต่างกัน เพราะฉะนั้นเป็นเรื่องจำเป็นมากที่ต้องตั้งคำถามว่าจะทดสอบไปเพื่ออะไร? โดยในการทดสอบของเราครั้งนี้ก็เพื่อตอบ 3 คำถามนั่นคือ\n ณ ปัจจุบัน ควรใช้ web server และ database server ด้วยจำนวนและขนาดเท่าไหร่? สเกลอย่างไรโดยใช้ทรัพยากรให้คุ้มค่ามากที่สุด ไม่เกิดปัญหาคอขวด (เช่นอัพ web server แต่ database ทำงานไม่ทัน ซึ่งจะทำให้การสเกลไม่สมบูรณ์และไม่เกิดประโยชน์)? การสเกลขึ้นในแต่ละระดับ จะสามารถรองรับผู้ใช้งานได้มากขึ้นเท่าไร?  คำถามทั้งสามถูกตั้งขึ้นเพราะจุดมุ่งหมายของเราคือ “คนเข้าเยอะขึ้น ระบบต้องไม่ล่ม” หากเราต้องสเกลขึ้นในระยะอันใกล้ถึงปานกลาง เราสามารถตัดสินใจได้ทันทีด้วยตัวเลขที่ได้จากการทดสอบครั้งนี้\nซึ่งหากโจทย์เราไม่ชัดเจน หรือไม่ตรงประเด็น คำตอบที่ได้ก็จะไม่มีประโยชน์ จะเห็นว่าเราไม่ได้ตั้งจุดประสงค์ด้าน response time เลย เพราะเราขอแค่ response time ให้อยู่ในเกณฑ์เดิมก็เพียงพอ\nเครื่องมือที่ใช้ เนื่องจากข้อจำกัดทางด้านเวลา เราจึงใช้ Apache JMeter เป็นเครื่องมือในการทดสอบ เพราะเคยใช้มาก่อนแล้วจึงไม่มี learning curve มากนัก\nApache JMeter ขนานนามตัวเองว่า “a 100% pure Java application designed to load test functional behavior and measure performance” ซึ่งถึงแม้ว่าจะเป็น 100% Java แต่ก็สามารถใช้ในโปรเจกต์ที่ใช้ภาษาอื่นๆ ได้ ที่เคยใช้มาก็มีทั้งการทดสอบกับ database server โดยตรง (ผ่าน JDBC) หรือยิงเข้า HTTP service SOAP service ฯลฯ ก็ได้\n  ออกแบบวิธีการทดสอบ คำถามที่สำคัญที่สุดของเราคือ จะทำอย่างไรให้มั่นใจว่าการทดสอบนั้นใกล้เคียงการใช้งานจริงมากที่สุด? เช่นหากเรายิงแต่หน้าแรกในขณะที่ผู้ใช้ส่วนใหญ่เข้าไปใช้หน้าอื่นๆ ซึ่งอาจจะกินโหลดเยอะกว่าหรือน้อยกว่าก็ได้ เราจึงใช้แนวทางนี้ในการออกแบบวิธีการทดสอบ\n ดึงข้อมูลการใช้งานเว็บไซต์ออกมาจาก Google Analytics สร้าง test cases ที่เทียบเท่าใน Apache JMeter ทั้งในแง่ของ active users, pageviews และหน้าที่ผู้ใช้เข้าถึง ทดสอบยิงโหลดเท่ากับจำนวนที่ได้จาก Google Analytics แล้วเทียบกับ New Relic และ Amazon CloudWatch ว่า CPU load / memory usage ที่คล้ายคลึงกับ production environment หรือไม่  นอกจากนี้ ความรีบเร่งของเราทำให้เกิดความ “ลูกทุ่ง” ในการทดสอบหลายอย่าง เช่น\n ใช้เน็ตของบริษัทในการทดสอบ ซึ่งเป็นสายไฟเบอร์เหมือนบริษัททั่วไป ยิงทดสอบออกจาก iMac เครื่องเดียว ระบบที่ถูกทดสอบตั้งอยู่ที่ประเทศไอร์แลนด์ ฝั่ง business ไม่ได้ตั้ง expected load มา  เราจึง​ “แก้เกม” ดังนี้\n เปิด activity monitor และใช้ speed test เพื่อเช็คความเร็ว download/upload สูงสุดของอินเตอร์เน็ต (ทดสอบทั้ง server ไทยและยุโรป) เปิด activity monitor เพื่อเช็คว่าไม่มีคอขวดทาง CPU/memory/disk ระหว่างทดสอบ เช็คด้วย New Relic APM ว่า requests per minute เพิ่มขึ้นตามแผนทดสอบ ยิงโหลดไปยังไฟล์ robots.txt เพื่อเช็ค response time แล้วใช้ค่านี้เป็น baseline ในเมื่อไม่มี expected load มาให้ เราจึงตั้ง configurations ในการสเกลหลายๆ แบบ และลองทดสอบไปทีละ configuration และสรุปผลออกเป็นตาราง  และนี่คือหน้าตาของ Test Plan ที่ถูกสร้างขึ้นใน Apache JMeter\n  หน้าตา Test Plan ที่ถูกสร้างขึ้นใน Apache JMeter\nนอกจากตัวโปรแกรม Apache JMeter แล้ว ในรูปด้านบนเราเพิ่ม jmeter plugins (http://jmeter-plugins.org/) เพื่อเพิ่มฟีเจอร์ที่ช่วยอำนวยความสะดวกในการทำการทดสอบด้วยดังนี้\n jp@gc — Stepping Thread Group: สำหรับใส่จำนวนผู้ใช้จำลอง ตั้งแต่จุดที่เริ่มต้นทดสอบและเพิ่ม/ลดจำนวน thread ตามระยะเวลาได้อย่างสะดวก jp@gc — Response Time vs Threads: เป็นหน้าหลักที่เราใช้ตรวจสอบการตอบสนองของระบบ เราสามารถเช็คได้ว่าระบบเริ่มรองรับไม่ไหวจากกราฟ Response Time ที่เริ่มทะยานขึ้นได้ jp@gc — Active Threads Over Time: สำหรับเช็คจำนวนผู้ใช้ที่เราจำลองขึ้น ณ จุดใดจุดหนึ่งของการทดสอบ jp@gc — Response Codes per Second: สำหรับตรวจสอบว่าระบบยังตอบสนองกลับมาเป็น 200 OK อยู่ ไม่ใช่ว่า response กลับมาเร็วแต่เป็น 500 Internal Server Error ฯลฯ jp@gc — Response Times Distribution: แสดง distribution graph ให้เห็นว่าการกระจายตัวของ response time จำแนกตามหน้าที่ยิง  ผลลัพธ์ ขออนุญาตแสดงเป็น screen capture ของแง่มุมต่างๆ ที่เราสามารถสรุปได้จากข้อมูลที่ได้มา\nด้านล่างเป็นกราฟ response time vs active threads แสดงให้เห็นว่าระบบตอบสนองได้เสถียรดีไปตลอดจนถึง 400 threads กราฟสีฟ้าๆ คาดว่าเป็นปัญหาภายในเน็ตเวิร์คของบริษัทเอง ส่วนค่าแกน Y ที่สูงอย่าไปสนใจมันมากครับ เทสระบบอ้อมไปครึ่งโลก แถมทดสอบครั้งนี้ก่อนหน้าที่จะทำ optimization ด้วย\n  กราฟ response time vs active threads   เมื่อเห็นว่าระบบยังตอบสนองได้ดีจนถึง 400 active threads เราก็จัดการทดสอบอีกครั้งโดยเพิ่ม max. active threads ให้สูงขึ้นไปอีก กราฟด้านล่างแสดงให้เห็นชัดเจนว่าด้วย configuration นี้ ระบบเริ่มไม่เสถียรตั้งแต่ 400 threads เป็นต้นไป และแสดงให้เห็นด้วยว่า endpoint สีฟ้า ถึงแม้ response time จะสูสีกับคนอื่นมาตลอด กลายเป็นตัวแรกที่แสดงอาการเมื่อโหลดสูงขึ้น\nในบางครั้ง เมื่อเราเร่ง active threads ขึ้นไปเยอะมากๆ อยู่ดีๆ response time ก็ตกลงไปอย่างน่าแปลกใจ แต่เมื่อมาดูที่กราฟ response codes per second ก็ทำให้พบว่า response time ไม่ได้แปลว่าระบบทำงานได้ดีขึ้นที่จำนวน threads เยอะๆ แต่มันเริ่มพ่น error กลับมาแล้วต่างหาก จากนั้นเราสามารถย้อนกลับไปดูที่กราฟ active threads over time ได้ว่า ณ เวลานั้นมี active threads เท่าไร\n  กราฟ response codes per second ทำให้เรารู้ว่า response time ที่แลดูนิ่งๆ ช่วงนาทีที่ 17 เป็นต้นไปไม่ใช่เพราะระบบทำงานดีขึ้น แต่เป็นเพราะมันเริ่มล่มแล้วต่างหาก   เมื่อเราทดสอบซ้ำๆ กับหลายๆ combination ทำให้เราสามารถสรุปผลออกมาเป็นตาราง ซึ่งตอบคำถามตั้งต้นของเราได้\n ณ ปัจจุบัน ควรใช้ web server และ database server ด้วยจำนวนและขนาดเท่าไหร่? สเกลอย่างไรโดยใช้ทรัพยากรให้คุ้มค่ามากที่สุด ไม่เกิดปัญหาคอขวด (เช่นอัพ web server แต่ database ทำงานไม่ทัน ซึ่งจะทำให้การสเกลไม่สมบูรณ์และไม่เกิดประโยชน์)? การสเกลขึ้นในแต่ละระดับ จะสามารถรองรับผู้ใช้งานได้มากขึ้นเท่าไร?    ผลลัพธ์ (แถม) เนื่องจากระบบที่ทดสอบมี New Relic APM (Application Performance Monitoring), New Relic Servers (Server Monitoring) และ Amazon CloudWatch อยู่แล้ว เราจึงใช้อย่างเต็มที่เพื่อเก็บข้อมูลอื่นๆ ซึ่งทำให้เราเข้าใจระบบของเรามากขึ้นไปอีก\n  New Relic ช่วยให้เราสามารถสังเกตการณ์โหลดฝั่ง web server ไปพร้อมๆ กันระหว่างการทดสอบ ทำให้เราเห็นการทำงานของระบบมากขึ้น (ใช้ AWS Cloudwatch ฯลฯ แทนก็ได้นะ)     หน้าตาของ Amazon CloudWatch ฝั่ง Database ทำให้เราสังเกตการณ์โหลดบนฐานข้อมูลได้เช่นกัน   Load testing ก่อนและหลังทำ code optimization หลังจากที่ได้ผลลัพธ์ข้างต้น เราได้หยิบ 2 endpoints มาทำ code optimization เพื่อให้โค๊ดใช้ทรัพยากรระบบลดลง ปรากฎว่าการเปรียบเทียบผลลัพธ์ระหว่างก่อนและหลังการทำ optimization ยิ่งมีความน่าสนใจเข้าไปอีก เพราะนอกจากมันจะทำให้ endpoint ทั้งสองประมวลผลเร็วขึ้นแล้ว ยังทำให้ระบบโดยรวมมี response time เร็วขึ้นสูงสุดกว่า 5 เท่า แต่ความเสถียรกลับผันผวนมากขึ้นตั้งแต่ 320 threads ขึ้นไป (ยังเร็วกว่าก่อน optimization อยู่ดี)\nซึ่งแสดงให้เห็นว่าการทำ load testing เป็นระยะๆ จะทำให้เราเห็นและทำความเข้าใจพฤติกรรมของระบบได้ดีขึ้น\n  เราทำ code optimization ไปเพียง 2 endpoints แต่ระบบโดยรวมกลับเร็วขึ้นทั้งหมด ถึงแม้ว่า response time เริ่มผันผวนเร็วขึ้นกว่าเดิม   ทิ้งท้าย นอกจากการทำ load testing ทำให้เรารู้ว่าระบบของเราสามารถรองรับผู้ใช้ได้มากเท่าไรแล้ว ยังทำให้เราเข้าใจพฤติกรรมของระบบมากขึ้น เช่นความสัมพันธ์ระหว่างโหลดของ web server และ DB server หรือแม้กระทั่งใช้เป็นข้อมูลเบื้องต้นในการทำ code optimization ต่อไป\nอย่างไรก็ตาม การทดสอบที่เกิดขึ้นด้านบนนี้ก็อยู่บนพื้นฐานของความ “ลูกทุ่ง” อยู่มาก เพื่อแลกมากับความรวดเร็วในการทดสอบ ทั้งนี้เราก็ได้รวบรวมข้อสังเกตเพื่อพัฒนาการทดสอบของเราในโอกาสต่อๆ ไปดังนี้\n ต้องทำ performance testing อย่างสม่ำเสมอ เพราะเราไม่รู้ว่าฟีเจอร์ที่เปลี่ยนแปลงไป จะมีผลกระทบต่อระบบโดยรวมอย่างไร เราปิด caching ทิ้งระหว่างการทดสอบ เนื่องจากข้อจำกัดด้านเวลาทำให้ไม่สามารถออกแบบ test plan ที่ซับซ้อนขึ้นได้ การทำ performance testing ที่ผลลัพธ์เที่ยงตรงมากขึ้นและทดสอบด้วย concurrent users จำนวนมากขึ้น ควรย้ายไปใช้บริการ Cloud Load Testing เช่น Load Impact, Flood.io, Blitz.io ฯลฯ ควรจัดหาวิธีการเก็บบันทึกผลลัพธ์อย่างเป็นระบบ เพื่อให้สามารถเปรียบเทียบผลลัพธ์ระหว่างการทดสอบแต่ละครั้งได้ ยังมีตัวแปรอื่นๆ ที่สำคัญที่เรา ไม่ได้ทดสอบในครั้งนี้ เช่น stress test, soak test ฯลฯ ซึ่งล้วนแล้วจะทำให้ผลการทดสอบเชื่อถือได้มากขึ้น และครอบคลุมการใช้งานจริงของระบบมากขึ้น  หากท่านใดมีความคิดเห็นอื่นๆ เกี่ยวกับการทดสอบครั้งนี้ เรายินดีรับคำแนะนำและปรับปรุงบทความเพื่อให้เป็นประโยชน์ต่อสาธารณะมากขึ้นครับ\nอ้างอิง  Apache JMeter Performance vs. load vs. stress testing - Grig Gheorghiu แนวทางการทำ Load Testing แบบง่ายๆ - somkiat.cc  "},{"idx":29,"href":"/90-about/donations/","title":"Donations","content":" Donations Social and Environmental Issues Recurring  COTAP - 10 USD/month (~1 CO2-tonne/month) since Aug 2019  Software I rely on many of the quality software below to improve my life. Many of them helped me making a living for the past few years. The people behind these great products below generously release their full (or very close to full) featured software without strict obligations to pay.\nApart from my contributions to open source and social causes, these are direct monetary contributions that I have made so far towards those software projects. I hope to contribute more in the coming years.\nI am extremely grateful to live during this time. You have made this world a better place to live in.\nRecurring  iTerm2 - 5 USD/month since Dec 2017 Homebrew - 5 USD/month since Dec 2017  One-time  CreativeCommons - 20 USD (2018) MyEtherWallet - 10 DAI (2018) Etherscan - 10 DAI (2018) ETH Gas Station - 10 DAI (2018) Transmission - 10 USD (2017) VideoLAN - 10 USD (2017) SMS Backup+ - 5 USD (2017) Authenticator Plus - 1 USD (2017, the author does not accept any other amount) Sublime Text - 80 USD (2015, not quite donation but I consider it a voluntary payment) Wikipedia - 7 USD (2010), 7 USD (2014) Cyberduck - 5 EUR (2010)  Pending  byobu Sequel Pro Have I Been Pwned Vim Soda Reloaded Read the Docs Daniel Stenberge - The creator of curl  Projects I wish I could pay for (they\u0026rsquo;re not accepting payments)  Duplicity  "}];window.bookSearch={pages:pages,idx:lunr(function(){this.ref("idx");this.field("title");this.field("content");pages.forEach(this.add,this);}),}})();